{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Hagmann connectome with Brodmann areas\n",
    "\n",
    "Hagmann presented a connectome in [Mapping the Structural Core of Human Cerebral Cortex](https://doi.org/10.1371/journal.pbio.0060159) and published the data. This notebook takes the published data, produces a [NetworkX graph](https://networkx.github.io/documentation/stable/index.html), and writes it to disk in [gpickle](https://docs.python.org/3/library/pickle.html) format.\n",
    "\n",
    "1. Download Hagmann connectome from TheVirtualBrain github\n",
    "2. Download Brodmann areas volume from MRIcron github\n",
    "3. Load data\n",
    "4. Build a graph and write it to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Hagmann connectome from TheVirtualBrain github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://github.com/the-virtual-brain/tvb-data/raw/master/tvb_data/connectivity/connectivity_998.zip'\n",
    "\n",
    "r = requests.get(url)  \n",
    "with open('./connectivity_998.zip', 'wb') as f:\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import unpack_archive\n",
    "unpack_archive('./connectivity_998.zip', 'connectivity_998/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Brodmann areas volume from MRIcron github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174606"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "url = \"https://github.com/neurolabusc/MRIcron/raw/master/niftiview7/templates/brodmann.nii.gz\"\n",
    "brodmann_filename = url.rsplit('/', 1)[1]\n",
    "r = requests.get(url)\n",
    "open(brodmann_filename, 'wb').write(r.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load broadmann volume and compute inverse transform\n",
    "brodmann_nii = nib.load(brodmann_filename)\n",
    "inv_transform = np.linalg.inv(brodmann_nii.affine)\n",
    "\n",
    "# read nodes region names and centers\n",
    "centres = np.genfromtxt('connectivity_998/centres.txt',\n",
    "                        dtype='|U256,i,i,i',\n",
    "#                        encoding='utf-8',\n",
    "                        names=['name','x','y','z'])\n",
    "\n",
    "# Read labels\n",
    "labels = np.genfromtxt('connectivity_998/raw_order_labels.txt',\n",
    "                        dtype='|U256').tolist()\n",
    "\n",
    "# It seems there are inconsistencies in region names, between centres and labels. Fix it\n",
    "ind = centres['name'] == 'rBSTS'\n",
    "centres['name'][ind] = 'rBTST'\n",
    "ind = centres['name'] == 'lBSTS'\n",
    "centres['name'][ind] = 'lBTST'\n",
    "\n",
    "\n",
    "# convert nodes region names to dict\n",
    "centres_list = list()\n",
    "positions_list = list()\n",
    "for idx, r in enumerate(centres):\n",
    "    centres_list.append(r['name'])\n",
    "    positions_list.append([r['x'], r['y'],r['z']])\n",
    "    \n",
    "    \n",
    "weights = np.genfromtxt('connectivity_998/weights.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a graph and write it to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Create a graph from weighted adjacency matrix\n",
    "weights_graph = nx.from_numpy_matrix(weights)\n",
    "\n",
    "# Create a graph from nodes' positions\n",
    "graph = nx.Graph()\n",
    "graph.add_nodes_from(range(0,len(positions_list)))\n",
    "\n",
    "for n, p in enumerate(positions_list):\n",
    "    graph.node[n]['x'] = p[0]\n",
    "    graph.node[n]['y'] = p[1]\n",
    "    graph.node[n]['z'] = p[2]\n",
    "    \n",
    "    point_in_volume = [int(p[0]+inv_transform[0,3]),\n",
    "                       int(p[1]+inv_transform[1,3]),\n",
    "                       int(p[2]+inv_transform[2,3])]\n",
    "    \n",
    "    graph.node[n]['brodmann_area'] = brodmann_nii.get_data()[point_in_volume[0],\n",
    "                                                  point_in_volume[1],\n",
    "                                                  point_in_volume[2],]\n",
    "    \n",
    "# Copy weighted edges\n",
    "graph.add_weighted_edges_from(weights_graph.edges(data='weight'))\n",
    "\n",
    "# Write to disk\n",
    "nx.write_gpickle(graph,'Hagmann_998.gpickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate some signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(998, 120000)\n"
     ]
    }
   ],
   "source": [
    "signals = np.tile(np.linspace(0,12000-1,120000), (998,1))\n",
    "idx = int(998/2)\n",
    "signals[0:idx,:] = signals[0:idx,:]+np.pi \n",
    "print(signals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = np.sin(signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=998, n_times=120000\n",
      "    Range : 0 ... 119999 =      0.000 ...   119.999 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "info = mne.create_info(998, 1000, 'eeg')\n",
    "raw = mne.io.RawArray(signals, info)\n",
    "#raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This filename (sub-mni_sim-simplehalf.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, raw.fif.gz, raw_sss.fif.gz or raw_tsss.fif.gz\n",
      "Writing /Users/spherik/Documents/DevLibs/python_for_brain/hagmann_connetome/sub-mni_sim-simplehalf.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-0c772cea1daf>:1: RuntimeWarning: This filename (sub-mni_sim-simplehalf.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, raw.fif.gz, raw_sss.fif.gz or raw_tsss.fif.gz\n",
      "  raw.save('sub-mni_sim-simplehalf.fif')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/spherik/Documents/DevLibs/python_for_brain/hagmann_connetome/sub-mni_sim-simplehalf.fif [done]\n"
     ]
    }
   ],
   "source": [
    "raw.save('sub-mni_sim-simplehalf.fif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
