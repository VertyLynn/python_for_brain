{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Hagmann connectome with Brodmann areas\n",
    "\n",
    "Hagmann presented a connectome in [Mapping the Structural Core of Human Cerebral Cortex](https://doi.org/10.1371/journal.pbio.0060159) and published the data. This notebook takes the published data, produces a [NetworkX graph](https://networkx.github.io/documentation/stable/index.html), and writes it to disk in [gpickle](https://docs.python.org/3/library/pickle.html) format.\n",
    "\n",
    "1. Download Hagmann connectome from TheVirtualBrain github\n",
    "2. Download Brodmann areas volume from MRIcron github\n",
    "3. Load data\n",
    "4. Build a graph and write it to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Hagmann connectome from TheVirtualBrain github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://github.com/the-virtual-brain/tvb-data/raw/master/tvb_data/connectivity/connectivity_998.zip'\n",
    "\n",
    "r = requests.get(url)  \n",
    "with open('./connectivity_998.zip', 'wb') as f:\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import unpack_archive\n",
    "unpack_archive('./connectivity_998.zip', 'connectivity_998/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Brodmann areas volume from MRIcron github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "url = \"https://github.com/neurolabusc/MRIcron/raw/master/niftiview7/templates/brodmann.nii.gz\"\n",
    "brodmann_filename = url.rsplit('/', 1)[1]\n",
    "r = requests.get(url)\n",
    "open(brodmann_filename, 'wb').write(r.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load broadmann volume and compute inverse transform\n",
    "brodmann_nii = nib.load(brodmann_filename)\n",
    "inv_transform = np.linalg.inv(brodmann_nii.affine)\n",
    "\n",
    "# read nodes region names and centers\n",
    "centres = np.genfromtxt('connectivity_998/centres.txt',\n",
    "                        dtype='|U256,i,i,i',\n",
    "                        encoding='utf-8',\n",
    "                        names=['name','x','y','z'])\n",
    "\n",
    "# Read labels\n",
    "labels = np.genfromtxt('connectivity_998/raw_order_labels.txt',\n",
    "                        dtype='|U256').tolist()\n",
    "\n",
    "# It seems there are inconsistencies in region names, between centres and labels. Fix it\n",
    "ind = centres['name'] == 'rBSTS'\n",
    "centres['name'][ind] = 'rBTST'\n",
    "ind = centres['name'] == 'lBSTS'\n",
    "centres['name'][ind] = 'lBTST'\n",
    "\n",
    "\n",
    "# convert nodes region names to dict\n",
    "centres_list = list()\n",
    "positions_list = list()\n",
    "for idx, r in enumerate(centres):\n",
    "    centres_list.append(r['name'])\n",
    "    positions_list.append([r['x'], r['y'],r['z']])\n",
    "    \n",
    "    \n",
    "weights = np.genfromtxt('connectivity_998/weights.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a graph and write it to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Create a graph from weighted adjacency matrix\n",
    "weights_graph = nx.from_numpy_matrix(weights)\n",
    "\n",
    "# Create a graph from nodes' positions\n",
    "graph = nx.Graph()\n",
    "graph.add_nodes_from(range(0,len(positions_list)))\n",
    "\n",
    "for n, p in enumerate(positions_list):\n",
    "    graph.node[n]['x'] = p[0]\n",
    "    graph.node[n]['y'] = p[1]\n",
    "    graph.node[n]['z'] = p[2]\n",
    "    \n",
    "    point_in_volume = [int(p[0]+inv_transform[0,3]),\n",
    "                       int(p[1]+inv_transform[1,3]),\n",
    "                       int(p[2]+inv_transform[2,3])]\n",
    "    \n",
    "    graph.node[n]['brodmann_area'] = brodmann_nii.get_data()[point_in_volume[0],\n",
    "                                                  point_in_volume[1],\n",
    "                                                  point_in_volume[2],]\n",
    "    \n",
    "# Copy weighted edges\n",
    "graph.add_weighted_edges_from(weights_graph.edges(data='weight'))\n",
    "\n",
    "# Write to disk\n",
    "nx.write_gpickle(graph,'Hagmann_998.gpickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
